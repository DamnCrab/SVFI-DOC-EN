---
title: Advanced Content Detail
date: 2022-08-26 15:48:00
permalink: /pages/052617/
---

There are seven columns in the advanced settings

<div align=center>
<img src="/Statics/UserGuide/26.png"  width=300>
</div>

## Workflow Recovery

<div align=center>
<img src="/Statics/UserGuide/13.png"  width=300>
</div>

- Auto Configuration

>When you encounter a situation where the program exits due to a power failure in the middle of a task or other circumstances other than terminating the task, you can restore the last block position by clicking "**Automatically find progress**".

::: warning
Before clicking this button, please click on the task entry you want to resume. Then click on "**One click to fill frames**" and a pop-up window will appear to confirm the starting position of the fill frames.
:::

<div align=center>
<img src="/Statics/UserGuide/6.png"  width=300>
</div>

- StartPoint and EndPoint

>You can select the time period you need to make up the frames, this function does not support task progress recovery

<div align=center>
<img src="/Statics/UserGuide/7.png"  width=300>
</div>

>**Format: HH:MM:SS**

::: warning
This function does not support Workflow Recovery
:::

- Start From Chunk and Start Frame(used when automatic progress search fails or when you need to manually specify the starting position of the complementary frame)

>Can be used to manually resume the progress

- Starting block count = number of **last chunk exported in the output folder + 1** (e.g. for chunk-001 in the figure, the starting block count should be **1+1=2**)
- Starting input frame count = ` single output block size * (starting block count - 1)` in the output quality settings (rendering settings)

<div align=center>
<img src="/Statics/UserGuide/8.png"  width=300>
</div>

<div align=center>
<img src="/Statics/UserGuide/9.png"  width=300>
</div>

<div align=center>
<img src="/Statics/UserGuide/10.png"  width=300>
</div>

As shown above, a video chunk has 1000 frames

- Reset

>The starting block and the starting input frame number can be returned to their original values, ** and the frames can be made up from the zero moment. **

<div align=center>
<img src="/Statics/UserGuide/11.png"  width=300>
</div>

<div align=center>
<img src="/Statics/UserGuide/12.png"  width=300>
</div>

- Fast Mode

>When you need to resume the task progress, turn this on to **reduce the time required for the program to resume progress**, but turning it on may cause **synchronization of audio and video**, **not recommended**.

<div align=center>
<img src="/Statics/UserGuide/13.png"  width=300>
</div>

## Scene Detection

- Enable Scene Detection

>Recognize scene switching

>In order to avoid the **jelly** effect when scene switching during frame filling, it is recommended that you turn on the transition recognition.

>After you check the box to turn on transition recognition, the parameter value below is usually 12.

>If you find that there are more misjudgments in the process of frame filling, you can consider adjusting it to 15; when facing the situation that there are more misjudgments, you can consider adjusting the parameter value to 9.

**As shown in the picture: Jelly is generated by the transition error**

<div align=center>
<img src="/Statics/UserGuide/14.png"  width=300>
</div>
<div align=center>
<img src="/Statics/UserGuide/15.png"  width=300>
</div>

- Use fixed transition recognition (use a fixed threshold to determine the difference between each frame to recognize transitions)

::: warning
It is not recommended to enable this feature
:::

>When using this feature, you need to turn on the "Enable transition recognition" feature.

>It is recommended to set the parameter to 40 if the complementary video is a live-action video, and to 50 or 60 if the complementary video is anime.

- Use frame blending for transitions

>The traditional method is to copy the previous frame and use it as a transition frame, this method is to mix the two frames (shadow overlay)

- Output transition frames

> Output the frames that are transitions in the video (with judgment information)

## Frame Deduplication (Improve video smoothness)

<div align=center>
<img src="/Statics/UserGuide/16.png"  width=300>
</div>

- Do not remove duplicate frames

>Do not use this feature

- Single recognition: this function may be used when making up frames for anime videos or real videos with repeated frames

>If the parameter value is set too high, it will cause the software to make up frames too difficult beyond the ability of AI to make up frames**, which will produce **serious distortion**.

>If you want to make up longer anime, it is recommended to set the parameter value to 0.2 or 0.1, otherwise the character will have the problem of "mouth not closing".

>This mode is also the simplest mode in principle, but it is also relatively stable to use.

- Remove 1 shot N: This function is designed for animation frame extraction, please choose to turn it on or off according to your needs.

>Remove 1 beat 2: Some of the material performs better, but in most cases, it cannot completely remove the duplicate frames, and it is easy to introduce lag.

>Remove 1 beat 3: Remove 1 beat 2 and 1 beat 3, commonly used in anime variable speed frame filling, anime editing, remove heavy more thoroughly, smoothness MAX, but will increase certain jelly.

>Remove 1 beat 4:... and so on

:::warning
Due to the limited ability of AI frame filler in anime frame filler at this stage, choosing de-weighting will increase the amplitude of movement between frames, resulting in frame distortion when filling frames, please choose the best de-weighting mode by yourself for each input video control variable for multiple trials.

It is recommended that you choose the de-duplication mode carefully, and it is not recommended to turn on de-duplication if you are making up frames for the whole movie.
:::

## Output Resolution Settings

- Output file resolution

>Resolution of the screen is adjusted first, and then the frame is made up afterwards (with presets) 

- Black border length

>Can be used to crop the black edge in the video, you need to specify the width and height manually 

>Example: the original film 3840x2160, the actual screen resolution 3840x1620, then here the ** high ** fill 270, calculation method (original film height - actual height) ÷ 2, and in the output resolution preset select custom, fill 3840 1620.

>If you use AI super division, the original film refers to the output video

>Example: input video 1920x1080, actual resolution 1920x800, super split 2 times output 3840x1600, black edge height fill 280, output resolution custom 3840 1600.

- After processing, fill in the black edge

>Fill in the frames after removing the black edge, and add the black edge back automatically after filling in the frames.

<div align=center>
<img src="/Statics/UserGuide/17.png"  width=300>
</div>
<div align=center>
<img src="/Statics/UserGuide/18.png"  width=300>
</div>

- Using AI Super Score

::: tip
This feature requires the purchase of the [Pro DLC](https://store.steampowered.com/app/1718750/SVFI_Professional/)
:::

>Make the video picture clearer, currently support **realCUGAN, realESRGAN, Anime4K, waifu2x, waifuCuda** and other hyper-segmentation algorithms.

<div align=center>
<img src="/Statics/UserGuide/19.png"  width=300>
</div>

##  An introduction to the superscore model (the larger the speed tag the faster, the larger the quality tag)

>realCUGAN Very good on anime (Speed 2, Quality 3)

>realESRGAN 3D/2D is better for anime (very slow) (speed 0.5, quality 2.5)

>waifu2x better for 2D anime input (faster) (classic superscoring algorithm) (speed 5, quality 1.5)

>waifuCuda for anime (stronger effect, slower speed than waifu2x) (speed 2, quality 2.5)

>Anime4K for anime and manga (super fast) (speed 10, quality 1.2) 

- **realCUGAN**

>pro model for enhanced version (see the official introduction of ailab/Real-CUGAN at main - bilibili/ailab (github.com))

>Models with the word conservative are conservative classes

>Models with no-denoise behave without noise reduction

>Models with denoise show noise reduction, the number after it represents the noise reduction intensity

>up2x means 2x amplification, 3x, 4x similar

- **ncnnCUGAN**

NCNN version of >CUGAN (for A card, N card, I card), introduction as above

- **waifuCuda**

>Only one model at present, suitable for anime input

- **realESR**

>RealESRGAN model tends to be brainstorming, the picture is clearer and more vivid

>RealESRNet model tends to smear, but the picture keeps the original color 

>The model with anime label is for anime super score, and the speed is slightly faster than the first two. 

>anime is the official model, anime_110k is the self-training model

>RealESR_RFDN is a self-training hyper-segmentation model, which is fast and suitable for anime input.

- **Anime4K**

>default use Anime4K_Upscale_x2_A

- **waifu2x**

>cunet model for anime superscale 

>photo model is used for realistic shooting

>anime for anime superscale

- Load graphics card

>Specify which graphics card to use for superscoring

- Hyperscore algorithm

>Select the algorithm to use for superscoring

- Superscoring model multiplier:

>The hyper-segmentation multiplier of the currently selected model

- Transfer resolution ratio

>First scale the original video by the percentage set by the user, and then superscale it.

>**Example: original video 1920x1080, transfer resolution ratio 50%, model magnification 4x**

>Running process: 1920x1080 -> 960x540 (under scaling) -> 3840x2160 (super resolution)

- RealCUGAN cutting mode (realCUGAN special) (the more you cut the more video memory left)

>No Tile: no cutting

>1/2 on Width: Split in two horizontally

>1/2 on both W and H: split into two horizontally and vertically

>1/3 on w & h: cut in thirds horizontally and vertically

>1/4 on w & h: cut in quarters horizontally and vertically

- RealCUGAN low memory mode (for realCUGAN) (when the graphics card is low on video memory)

>None: Do not use low memory mode

>Low VRAM Mode: Enable low memory mode

- Cut block size (not recommended when using realCUGAN)

>There is a preset for memory size, you can also choose to customize it.

<div align=center>
<img src="/Statics/UserGuide/20.png"  width=300>
</div>

- Overscoring using half precision

>It is recommended to turn on, which can significantly reduce the memory consumption and has less impact on the quality of the screen. (But for nVidia's 10xx series Pascal architecture graphics cards will slow down the speed of overscoring)

- TTA (only ncnnCUGAN has this feature): sacrifice a lot of speed, a small increase in image quality

## Output Quality（Quality of pressing parameters）

<div align=center>
<img src="/Statics/UserGuide/21.png"  width=300>
</div>

- Render Quality CRF

> Used to adjust the quality loss when exporting video, positively correlated with **output bitrate**. Using different compression encodings and compression presets will have an impact on CRF.

**The CRF value parameter is generally 16**, when there is no loss to the naked eye; for H.265 encoding, the bitrate will drop significantly. **Please use the quality of the picture seen by the naked eye to evaluate whether the CRF value size is reasonable. **
If it is used as **collection CRF value parameter can be set to 12**. **The smaller the CRF value, the smaller the loss to the picture after the operation process, and the larger the volume (bit rate) of the exported finished video. **

  **Note: The same value, different encoders have different output quality**

- Target bitrate

>Optional as an alternative to Render Quality CRF, basically the same as PR, AE, DaVinci Resolve

- Encoders

  - **AUTO**
  Encoder options are automatically determined by the slider at the bottom of the software
  - **CPU**
  Selecting this compression, **the highest quality, but also the highest CPU usage**. **CPU performance** determines whether the frame fill or overscoring process will block (resulting in a drop in graphics card usage) and the length of time** for the final operation to complete**.
  - **NVENC**
  This option is only available for NVIDIA graphics cards** that support NVENC function.
  Please check the NVIDIA NVENC Gen.pdf in the installation directory to see if your card supports NVENC.
  - **VCE**
  This option is only available for AMD graphics cards** that support VCE function.
  - **QSV**
  This item is only for users with **Intel core graphics** (e.g. Intel UHD 630, IrisPro 580), do not select this item if you are not a user.

  ::: tip
  The following encoders require the purchase of the [Pro DLC](https://store.steampowered.com/app/1718750/SVFI_Professional/)
  :::

  - **NVENCC**
  **NVENCC** is an optimized version of **NVENC**, with faster processing speed and better quality of work.
  - **QSVENCC**
  **QSVENCC** is an optimized version of **QSV**, which completes tasks more efficiently.
  - **VCENCC**
  **VCENCC** is an optimized version of **VCE**, which completes tasks more efficiently.

Perceptual comparison.
| Encoders| Use Hardware| Speed| Quality| File Size| Selection Suggestions|
|--|--|--|--|--|--|--|--|--|
|CPU |CPU |Medium| High| Medium| For image quality and encoding stability as well as A-card users AU users choose|
|NVENC| N-Card| Fast| Medium| Large| The pursuit of both speed and quality, and less size sensitive users choose|
|QSV| Intel Core| Slow| Low| Small|	



- Select suppressed encoding

>For this feature, you need to have some general knowledge of **video compression**.

::: warning If you are not familiar with compression, please keep in mind the following rules.

- HDR output must be selected **H.265 10bit** encoding
- Always choose **H.265** encoding for resolutions above 2K (especially for 4K, 8K resolutions)
- If H.264 or H.265 encoding is a problem, use **ProRes** encoding. This encoding output is closest to lossless to the naked eye, has a great bitrate, and is an intermediate encoding format for editing work.
- H.265 fast encoding or ProRes encoding is recommended.
:::

- Select a pressing preset

>CPU: English meaning **the faster the speed the lower the quality of the work, and vice versa the higher the quality**.

>NVENC: It is recommended to choose p7 without any brain

>QSV: choose slow directly

>VCE: Directly choose quality

>NVENCC: Directly choose quality

>QSVENCC: Directly choose best

>VCENCC: select slow directly

- N-card hard-coded presets

>When you choose NVENC encoder, N card hard-code preset can reduce the size of the exported video with the same picture quality. 

- Default compression scheme

>Use the traditional compression scheme, which is compatible, the size of the exported video may increase.

:::tip
Enable this function can solve most broken pipe problems.
:::

- Audio duplexing to AAC

>Re-encode the audio (usually used for videos on upload platforms)
Compress all audio tracks in the video to **640kbps aac format**.

- Source HDR (HDR attribute of the original video)
  - **Auto**
  Auto recognition (automatically switches to CPU compression when HDR content is detected).
  - **Custom HDR**
  Custom HDR (HDR source data will not be written).
  - **HDR10**
  Basic, pervasive HDR format.
  - **HDR10+**
  HDR10+ (only supports frame fill by frame fill rate, no custom output frame rate).
  - **Dolby Vision**
  Dolby Vision (only supports frame by frame multiplier, can't customize the output frame rate).
  - **HLG**
  Sony's new technology (portable HDR workflow)

- One-touch HDR: Converts SDR video to HDR10+

>Four one-button HDR modes need to try the effect by yourself

## Decoding Quality Control

- Hardware decoding

>Eases the pressure of decoding large resolution video, but may **decrease picture quality** to some extent and cause the frame filler module to **burst memory** when video memory is tight.

- Fast frame splitting

>Fast frame splitting operation can **reduce decoding pressure**, but may **lead to color deviation**.

- High-precision optimization workflow

::: tip
This feature requires the purchase of [Pro DLC](https://store.steampowered.com/app/1718750/SVFI_Professional/)
:::

>If CPU performance is excessive, we recommend you to turn on this function to **resolve most of the screen color deviation problems** and to maximize the resolution of color deviation problems caused by HDR video compression. This function will **increase the CPU load** and even affect the frame fill speed.
Turning on this feature for superscoring will **turn off half-precision** (which requires more video memory). Please choose at your **discretion**.

- Turn on inverse interlacing

::: tip
This feature requires the purchase of the [Pro DLC](https://store.steampowered.com/app/1718750/SVFI_Professional/)
:::

>Use **ffmpeg** to inverse interlace the input **interlaced video**.

- Fast noise reduction

::: tip
This feature requires the purchase of [Pro DLC](https://store.steampowered.com/app/1718750/SVFI_Professional/)
:::

>Fast" option under this section should be left off if you don't need it specifically, otherwise it will **slow down the task processing**.

::: tip
It is recommended to test whether this option helps to improve the quality of the screen by controlling the variables yourself.

Not compatible with high precision optimization workflow
:::

## Custom encoding settings

- Specify the number of encoding threads

> When the encoder is CPU, there is a chance to control the CPU usage to control the rendering speed .

- Custom suppression parameters

>This function is a professional option (note that the number of input items must be **even**), generally fill in the format: -x265-params||ref=4:me=3:subme=4:rd=4:merange=38:rdoq-level=2:rc-lookahead=40:scenecut=40:strong -intra-smoothing=0

- Time Remapping: Change the speed of the video

::: tip
This feature requires the purchase of the [Pro DLC](https://store.steampowered.com/app/1718750/SVFI_Professional/)
:::

>This function is used to create "slow motion" footage.

>For example, if you set the output frame rate to 120 fps and the time remapping to 60 fps, the output effect is equivalent to 50% **playback speed slow motion**.

>In other cases, you can set the output frame rate yourself, **support decimal**.

  **(Animation material please turn on one shot three de-duplication** in **removal of repeated frames as far as possible or use software such as Premiere to reduce the frame rate of the original video to complete the removal of repeated frames to avoid lagging after remapping. (The original video frame rate is generally reduced to 8 or 12 fps)**

## IO Control

<div align=center>
<img src="/Statics/UserGuide/23.png"  width=300>
</div>

- Specify buffer memory size manually

>If the running memory is tight (less than 16G), it is recommended to **manually specify the buffer memory size** as 2-3G to avoid **out of memory(out of memory)** error.

- Single output block size

>For patch and press jobs, a small clip without audio will be output for every rendered frame of this value, to facilitate your **preview of the effect**.
The clips are generated in the output folder you set,** and merged into one file** after the fill frame or press job is completed.

- Keep the project folder after the task is completed

>Fix frames after completion** without deleting the chunk video generated in between**.

## Interpolation Settings

- **Safe frame rate**

>If the video is to be uploaded to the corresponding media platform for online viewing, please turn this on

- **Reverse optical flow**
  
>This feature allows the picture to be **more silky smooth** to some extent.

- **Absolutely smooth**
  
>This feature may make the screen **more silky smooth**, just turn it on by default (it will not be enabled when the software is running when it is not available)

- **Light stream scale**
  
>When the original video size is 1080P, the default on 0.5, 4K and above on 0.25, less than 1080P on 1.0

- **Interlaced complementary frames**
  
>Equivalent to special cutting (reduce image quality, reduce video memory consumption)

> Properly select this item can allow small memory graphics cards to make up for the large resolution (such as 4G to make up for 8K)

- **Load graphics card**
  
> Specify which graphics card to use to make up the frames

- **Filling algorithm**
  
>Select the frame filling algorithm (including RIFE, EISAI, IFUNet, IFRNet, DAIN, SoftSplat)

- **Fill frame model** (the larger the speed tag the faster, the larger the quality number)

::: tip
Models with the word `ncnn` use [ncnn](https://github.com/Tencent/ncnn) as the forward inference framework, which is compatible with N and A cards, while models without this word cannot be used with A and core graphics.
:::

 - rife

 >2.3: speed 5, mass 10

 >3.8 (must have bi-directional optical flow on): speed 4, quality 8

 >4.0 (rife is the first model that supports any moment, the following models are the same): speed 10, mass 4.5

 >4.1: velocity 7, mass 4

 >4.2: velocity 10, mass 5.5

 >rpr_v7_1.0: velocity 6, mass 7

 >rpr_v7_2.3: velocity 2.5, mass 8

 >rpr_v7_2.3_ultra: speed 2, mass 9.5-10

 >rpr_v7_2.3_ultra#2: velocity 1, mass 9.5-10

 - ncnn-rife

 >rife-v2.4: velocity 15, mass 9.5

 >rife-v3.1: speed 16, quality unknown, not recommended

 >rife-v4(support any moment): speed 20, mass 4.5

 - IFUNet (anime model) (mass to be determined) (supports any moment)

 >Baseline: Speed 2

 >Best: Speed 1

 >FT2: Speed 1

 - IFRNet(real & anime model)(speed 2.5 - 7)(quality to be determined)

 >IFRNet

 >IFRNet_large

 >IFRNet_small

 - EISAI (anime frame filling algorithm): only one model, speed 1, quality to be determined

 - ncnn_dain(traditional old algorithm, anime real shot are available)(support any moment): speed 0.1, quality 8, smoothness very high

 - Softsplat(experimental new algorithm)(support any moment)(make up several times the frame rate time is basically the same)

 >Baseline: not recommended

 >Finetuned: recommended

- **TTA mode**
  

::: tip
This feature requires the purchase of the [Pro DLC](https://store.steampowered.com/app/1718750/SVFI_Professional/)
:::

>Enable this function to **reduce screen jelly, reduce subtitle shake, and diminish the problem of disappearing objects**. Make the picture more **smooth and comfortable**

>** requires extra frame fill time, while some frame fill models do not support this feature**.

>The larger the number behind the fill, the slower and less jelly, usually fill 1 or 2 on the line

>Lateral, suitable for rife, 3.x series models

>Mid direction, suitable for rife, 2.x series models

- Output layer fine-tuning mode (only for experimental models)

>residual: it will make the picture blurred, but the structure is more complete

>direct: direct output, clearer picture

- **Bidirectional optical flow**

>speed is reduced by about half, the effect is slightly improved (rife 3.8 models must be on) (rife 4.x models are not supported at the moment).

- **Dynamic optical flow scale**
  

::: tip
This feature requires the purchase of the [Pro DLC](https://store.steampowered.com/app/1718750/SVFI_Professional/)
:::

>Dynamically select the optical flow scale during frame filling, which can reduce the problem of disappearing objects and reduce jelly.

## NCNN parameters

- Number of complementary frame threads

>default is 1, it has a chance to accelerate, but it is not recommended to open

## Custom preset bar 

- New preset based on current settings: Click on a preset after giving it a name to create a new preset 

- Remove current preset: Delete the currently selected preset 

- Apply preset: Load a previously saved preset and load the parameters automatically 

## Toolbox

- Convert video to GIF animations

>Generate high quality GIF animations 

- Loop Animations

>Just open by default 

- Merge existing chunks

>Merge scattered chunk clips 

- Merge audio and video

>Fill in the full path of the video (example: D:\01\myvideo.mp4)

>Fill in the audio path of the video (example: D:\01\myvideo.aac)

>or use a video to input audio (example: D:\01\otherVideo.mp4)

>output video path (example:D:\01\output.mp4)

- Export current settings to a text document

>Export settings information

- Debug

>Debug mode (more information will be output)

## Functions on the title bar (except for those that need to be specifically mentioned, you will understand after reading it)

<div align=center>
<img src="/Statics/UserGuide/24.png" width=300>
</div>

### Settings - Preferences

- Multitasking break interval

> Give the device a break every X hours (shortly suspend tasks)

- Select cache folder

>Same as marked in the figure

- After the completion of the supplementary frame task

> You can choose some automatic operations after frame completion

- Unavailable features

>Forcing the use of CPU for interpolation superscore (deprecated)

- Turn on expert mode

> Enabled by default, display all functions

- Parameter text preview before starting the task

>Click to start the supplementary frame before the pop-up box will pop up, you can browse through it to confirm that the parameter settings are correct and then perform supplementary frame or super resolution

- Clear the task list after the task is completed

Clean up the queue after all tasks in the list are completed

- use global settings

>Unified parameter setting for all tasks

- reckless exit

>Enabled by default, to forcibly end the software process (if you find that the video memory is occupied after closing the software, it is recommended to enable this)

- Original compression mode

> When suppressing tasks individually, operations such as deduplication of repeated frames are not enabled

- Turn on preview

> Opening the preview window when supplementing frames will slow down the running speed of the program to a certain extent

- Automatic error correction

>Automatically modify settings to prevent some errors

- Turn on quiet mode

>Does not launch black window when software starts (invalid function)

-Test Mode(Experiment)

> void function

- Window on top

Bring the window to the front (void function)
